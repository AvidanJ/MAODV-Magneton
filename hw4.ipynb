{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP5auuroeheHcwLoVGGFx8i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AvidanJ/MAODV-Magneton/blob/main/hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We ll load the diabetes dataset and\n",
        "split it into training and testing sets."
      ],
      "metadata": {
        "id": "dianNsv1ptZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhvHz6oCn3_5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets, linear_model, metrics\n",
        "\n",
        "# Load diabetes dataset\n",
        "diabetes = datasets.load_diabetes()\n",
        "diabetes_X = diabetes.data  # matrix of dimensions 442x10\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "diabetes_X_train = diabetes_X[:-20]\n",
        "diabetes_X_test = diabetes_X[-20:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "diabetes_y_train = diabetes.target[:-20]\n",
        "diabetes_y_test = diabetes.target[-20:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we ll create a linear regression model.\n",
        "Train the model using the training set and make predictions using the testing set and then calculate the mean squared error."
      ],
      "metadata": {
        "id": "DG2PClrPp0jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create linear regression object\n",
        "regr = LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(diabetes_X_train, diabetes_y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
        "\n",
        "# The coefficients\n",
        "print(\"Coefficients: \\n\", regr.coef_)\n",
        "# The mean squared error\n",
        "mean_squared_error = metrics.mean_squared_error(diabetes_y_test, diabetes_y_pred)\n",
        "print(\"Mean squared error: %.2f\" % mean_squared_error)\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhugQfdTpk-K",
        "outputId": "2758b147-9fb7-4f79-a1fe-8526eafafe1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: \n",
            " [ 3.06094248e-01 -2.37635570e+02  5.10538048e+02  3.27729878e+02\n",
            " -8.14111926e+02  4.92799595e+02  1.02841240e+02  1.84603496e+02\n",
            "  7.43509388e+02  7.60966464e+01]\n",
            "Mean squared error: 2004.52\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we initialize weights and bias and implement the gradient descent algorithm to minimize the mean squared error."
      ],
      "metadata": {
        "id": "WygpMOGfprXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "X = diabetes_X_train\n",
        "y = diabetes_y_train\n",
        "\n",
        "# Initialize weights and bias\n",
        "W = np.random.randn(X.shape[1])\n",
        "b = np.random.randn()\n",
        "\n",
        "learning_rate = 1e-2\n",
        "epochs = 100000\n",
        "\n",
        "# Gradient Descent\n",
        "for i in range(epochs):\n",
        "    # Calculate predictions\n",
        "    y_pred = X @ W + b\n",
        "\n",
        "    # Calculate error and cost\n",
        "    error = y_pred - y\n",
        "    mean_squared_error = metrics.mean_squared_error(y, y_pred)\n",
        "\n",
        "    # Calculate gradients\n",
        "    grad_w = X.T @ error / X.shape[0]\n",
        "    grad_b = np.mean(error)\n",
        "\n",
        "    # Update parameters\n",
        "    W -= learning_rate * grad_w\n",
        "    b -= learning_rate * grad_b\n",
        "\n",
        "    # Diagnostic output\n",
        "    if i % 5000 == 0:\n",
        "        print(f\"Epoch {i}: {mean_squared_error}\")\n",
        "\n",
        "# Display model accuracy and parameters\n",
        "y_pred_test = diabetes_X_test @ W + b\n",
        "MSE = metrics.mean_squared_error(diabetes_y_test, y_pred_test)\n",
        "print(\"-\"*40)\n",
        "print(\"\\nModel Weights:\\n\", W)\n",
        "print(\"-\"*40)\n",
        "print(\"The MSE on test set is:\", MSE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4tmuFdcp8M5",
        "outputId": "aee8d3fd-16db-4d53-ed53-7a191e7499a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: 29625.000799166075\n",
            "Epoch 5000: 4601.827816291452\n",
            "Epoch 10000: 3963.5969197047234\n",
            "Epoch 15000: 3631.536718740585\n",
            "Epoch 20000: 3438.925460296222\n",
            "Epoch 25000: 3314.9970722353028\n",
            "Epoch 30000: 3228.484341860233\n",
            "Epoch 35000: 3164.6652028801545\n",
            "Epoch 40000: 3115.963402456961\n",
            "Epoch 45000: 3078.0488931199193\n",
            "Epoch 50000: 3048.181821122119\n",
            "Epoch 55000: 3024.4808730706054\n",
            "Epoch 60000: 3005.5792836798023\n",
            "Epoch 65000: 2990.4485130007456\n",
            "Epoch 70000: 2978.2981826978553\n",
            "Epoch 75000: 2968.5133676749033\n",
            "Epoch 80000: 2960.6120070392017\n",
            "Epoch 85000: 2954.2143082352513\n",
            "Epoch 90000: 2949.019972499291\n",
            "Epoch 95000: 2944.790876463242\n",
            "----------------------------------------\n",
            "\n",
            "Model Weights:\n",
            " [  15.52417891 -195.44579415  480.4215076   304.98075517  -47.27423776\n",
            " -103.41503941 -209.53303482  132.1600588   398.56776707  124.83366785]\n",
            "----------------------------------------\n",
            "The MSE on test set is: 2124.8257258720264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean squared error obtained from the scikit-learn implementation serves as a reference, against which the mean squared error of the manually implemented gradient descent model is compared to ensure accuracy."
      ],
      "metadata": {
        "id": "KkTKIGl1qC83"
      }
    }
  ]
}